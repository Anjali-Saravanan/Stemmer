{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemmer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrd9K9tLOf51SOTwZUpqo9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anjali-Saravanan/Stemmer/blob/main/Stemmer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i6N1PSTu4-Z2"
      },
      "outputs": [],
      "source": [
        "# importing nltk library for stemming\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "Uj3jgNni7ACn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_words = [\"smiling\",\"writing\",\"eating\",\"singing\",\"dancing\", \"calculating\"]"
      ],
      "metadata": {
        "id": "D5-_UemS7B5H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for w in example_words:\n",
        "    #print(w)\n",
        "    stem1=ps.stem(w)\n",
        "    print(stem1)"
      ],
      "metadata": {
        "id": "wejT-hiV7HyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing modules \n",
        "from nltk.stem import PorterStemmer \n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "\n",
        "ps = PorterStemmer() \n",
        "sentence = \"Programers program with programing languages\"\n",
        "words = word_tokenize(sentence) \n",
        "print(words)\n",
        "for w in words: \n",
        "\tprint( ps.stem(w))"
      ],
      "metadata": {
        "id": "B6jlp8x47Ns1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "text = word_tokenize(\"And now for something completely different\")\n",
        "nltk.pos_tag(text)"
      ],
      "metadata": {
        "id": "pulg3Uy67TLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "text = word_tokenize(\"And now for something completely different\")\n",
        "print(text)"
      ],
      "metadata": {
        "id": "fSwQGCin7dP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python code to \n",
        "# demonstrate readlines() \n",
        "\n",
        "#L = [\"Statistics\", \"Machine Learning\", \"SRM\"]\n",
        "Text=\"A book is a medium for recording information in the form of writing or images, typically composed of many pages (made of papyrus, parchment, vellum, or paper) bound together and protected by a cover.\" \n",
        "\n",
        "#writing to file \n",
        "file1 = open('/content/myfile.txt', 'w') \n",
        "file1.writelines(Text) \n",
        "file1.close() \n",
        "\n",
        "# Using readlines() \n",
        "file1 = open('/content/myfile.txt', 'r') \n",
        "Lines = file1.readlines() \n",
        "\n",
        "#count = 0\n",
        "# Strips the newline character \n",
        "for line in Lines: \n",
        "\tprint(line+\"\\n\") "
      ],
      "metadata": {
        "id": "r6e5jThk7lKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# importing modules \n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('punkt')\n",
        "\n",
        "ps = PorterStemmer() \n",
        "\n",
        "#sentence = \"Programers program with programing languages\"\n",
        "for line in Lines: \n",
        "  words = word_tokenize(line) \n",
        "  print(words)\n",
        "\n",
        "for w in words: \n",
        "\tprint(w, \" : \", ps.stem(w))\n"
      ],
      "metadata": {
        "id": "zYoclR4T8G3H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}